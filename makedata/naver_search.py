import requests
import json
import urllib.parse
from bs4 import BeautifulSoup
import time
import re
import csv
import os
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
import random

class NaverSearchAPI:
    def __init__(self, client_id, client_secret):
        """
        ë„¤ì´ë²„ ê²€ìƒ‰ API í´ë˜ìŠ¤ ì´ˆê¸°í™”
        
        Args:
            client_id (str): ë„¤ì´ë²„ ê°œë°œìì„¼í„°ì—ì„œ ë°œê¸‰ë°›ì€ Client ID
            client_secret (str): ë„¤ì´ë²„ ê°œë°œìì„¼í„°ì—ì„œ ë°œê¸‰ë°›ì€ Client Secret
        """
        self.client_id = "nML9kslg3kN6ObjrujI3"
        self.client_secret = "UynDCaMJCt"
        self.base_url = "https://openapi.naver.com/v1/search"
    
    def _make_request(self, endpoint, query, display=10, start=1, sort="sim"):
        """
        ë„¤ì´ë²„ APIì— ìš”ì²­ì„ ë³´ë‚´ëŠ” ê³µí†µ ë©”ì„œë“œ
        
        Args:
            endpoint (str): API ì—”ë“œí¬ì¸íŠ¸ (blog, news, book, etc.)
            query (str): ê²€ìƒ‰ì–´
            display (int): ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥ ê±´ìˆ˜ (1~100)
            start (int): ê²€ìƒ‰ ì‹œì‘ ìœ„ì¹˜ (1~1000)
            sort (str): ì •ë ¬ ì˜µì…˜ (sim: ì •í™•ë„ìˆœ, date: ë‚ ì§œìˆœ)
        
        Returns:
            dict: API ì‘ë‹µ ê²°ê³¼
        """
        url = f"{self.base_url}/{endpoint}"
        
        headers = {
            "X-Naver-Client-Id": self.client_id,
            "X-Naver-Client-Secret": self.client_secret
        }
        
        params = {
            "query": query,
            "display": display,
            "start": start,
            "sort": sort
        }
        
        try:
            response = requests.get(url, headers=headers, params=params)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            print(f"API ìš”ì²­ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return None
    
    def search_blog(self, query, display=10, start=1, sort="sim"):
        """
        ë¸”ë¡œê·¸ ê²€ìƒ‰
        
        Args:
            query (str): ê²€ìƒ‰ì–´
            display (int): ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥ ê±´ìˆ˜ (1~100)
            start (int): ê²€ìƒ‰ ì‹œì‘ ìœ„ì¹˜ (1~1000)
            sort (str): ì •ë ¬ ì˜µì…˜ (sim: ì •í™•ë„ìˆœ, date: ë‚ ì§œìˆœ)
        
        Returns:
            dict: ë¸”ë¡œê·¸ ê²€ìƒ‰ ê²°ê³¼
        """
        return self._make_request("blog", query, display, start, sort)
    
    def search_news(self, query, display=10, start=1, sort="sim"):
        """
        ë‰´ìŠ¤ ê²€ìƒ‰
        
        Args:
            query (str): ê²€ìƒ‰ì–´
            display (int): ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥ ê±´ìˆ˜ (1~100)
            start (int): ê²€ìƒ‰ ì‹œì‘ ìœ„ì¹˜ (1~1000)
            sort (str): ì •ë ¬ ì˜µì…˜ (sim: ì •í™•ë„ìˆœ, date: ë‚ ì§œìˆœ)
        
        Returns:
            dict: ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼
        """
        return self._make_request("news", query, display, start, sort)
    
    def search_book(self, query, display=10, start=1, sort="sim"):
        """
        ì±… ê²€ìƒ‰
        
        Args:
            query (str): ê²€ìƒ‰ì–´
            display (int): ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥ ê±´ìˆ˜ (1~100)
            start (int): ê²€ìƒ‰ ì‹œì‘ ìœ„ì¹˜ (1~1000)
            sort (str): ì •ë ¬ ì˜µì…˜ (sim: ì •í™•ë„ìˆœ, date: ë‚ ì§œìˆœ)
        
        Returns:
            dict: ì±… ê²€ìƒ‰ ê²°ê³¼
        """
        return self._make_request("book", query, display, start, sort)
    
    def search_encyc(self, query, display=10, start=1):
        """
        ë°±ê³¼ì‚¬ì „ ê²€ìƒ‰
        
        Args:
            query (str): ê²€ìƒ‰ì–´
            display (int): ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥ ê±´ìˆ˜ (1~100)
            start (int): ê²€ìƒ‰ ì‹œì‘ ìœ„ì¹˜ (1~1000)
        
        Returns:
            dict: ë°±ê³¼ì‚¬ì „ ê²€ìƒ‰ ê²°ê³¼
        """
        return self._make_request("encyc", query, display, start)
    
    def search_movie(self, query, display=10, start=1):
        """
        ì˜í™” ê²€ìƒ‰
        
        Args:
            query (str): ê²€ìƒ‰ì–´
            display (int): ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥ ê±´ìˆ˜ (1~100)
            start (int): ê²€ìƒ‰ ì‹œì‘ ìœ„ì¹˜ (1~1000)
        
        Returns:
            dict: ì˜í™” ê²€ìƒ‰ ê²°ê³¼
        """
        return self._make_request("movie", query, display, start)
    
    def search_cafearticle(self, query, display=10, start=1, sort="sim"):
        """
        ì¹´í˜ê¸€ ê²€ìƒ‰
        
        Args:
            query (str): ê²€ìƒ‰ì–´
            display (int): ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥ ê±´ìˆ˜ (1~100)
            start (int): ê²€ìƒ‰ ì‹œì‘ ìœ„ì¹˜ (1~1000)
            sort (str): ì •ë ¬ ì˜µì…˜ (sim: ì •í™•ë„ìˆœ, date: ë‚ ì§œìˆœ)
        
        Returns:
            dict: ì¹´í˜ê¸€ ê²€ìƒ‰ ê²°ê³¼
        """
        return self._make_request("cafearticle", query, display, start, sort)
    
    def search_kin(self, query, display=10, start=1, sort="sim"):
        """
        ì§€ì‹iN ê²€ìƒ‰
        
        Args:
            query (str): ê²€ìƒ‰ì–´
            display (int): ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥ ê±´ìˆ˜ (1~100)
            start (int): ê²€ìƒ‰ ì‹œì‘ ìœ„ì¹˜ (1~1000)
            sort (str): ì •ë ¬ ì˜µì…˜ (sim: ì •í™•ë„ìˆœ, date: ë‚ ì§œìˆœ)
        
        Returns:
            dict: ì§€ì‹iN ê²€ìƒ‰ ê²°ê³¼
        """
        return self._make_request("kin", query, display, start, sort)
    
    def search_local(self, query, display=5, start=1, sort="random"):
        """
        ì§€ì—­ ê²€ìƒ‰
        
        Args:
            query (str): ê²€ìƒ‰ì–´
            display (int): ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥ ê±´ìˆ˜ (1~5)
            start (int): ê²€ìƒ‰ ì‹œì‘ ìœ„ì¹˜ (1~1000)
            sort (str): ì •ë ¬ ì˜µì…˜ (random: ì •í™•ë„ìˆœ, comment: ì—…ì²´ë¦¬ë·°ê°œìˆ˜ìˆœ)
        
        Returns:
            dict: ì§€ì—­ ê²€ìƒ‰ ê²°ê³¼
        """
        return self._make_request("local", query, display, start, sort)
    
    def search_image(self, query, display=10, start=1, sort="sim", filter="all"):
        """
        ì´ë¯¸ì§€ ê²€ìƒ‰
        
        Args:
            query (str): ê²€ìƒ‰ì–´
            display (int): ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥ ê±´ìˆ˜ (1~100)
            start (int): ê²€ìƒ‰ ì‹œì‘ ìœ„ì¹˜ (1~1000)
            sort (str): ì •ë ¬ ì˜µì…˜ (sim: ì •í™•ë„ìˆœ, date: ë‚ ì§œìˆœ)
            filter (str): í•„í„° ì˜µì…˜ (all: ì „ì²´, large: í° ì´ë¯¸ì§€, medium: ì¤‘ê°„ ì´ë¯¸ì§€, small: ì‘ì€ ì´ë¯¸ì§€)
        
        Returns:
            dict: ì´ë¯¸ì§€ ê²€ìƒ‰ ê²°ê³¼
        """
        url = f"{self.base_url}/image"
        
        headers = {
            "X-Naver-Client-Id": self.client_id,
            "X-Naver-Client-Secret": self.client_secret
        }
        
        params = {
            "query": query,
            "display": display,
            "start": start,
            "sort": sort,
            "filter": filter
        }
        
        try:
            response = requests.get(url, headers=headers, params=params)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            print(f"API ìš”ì²­ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return None

class NaverBlogSearchAPI:
    def __init__(self, client_id=None, client_secret=None):
        """
        ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰ API í´ë˜ìŠ¤ ì´ˆê¸°í™”
        
        Args:
            client_id (str): ë„¤ì´ë²„ ê°œë°œìì„¼í„°ì—ì„œ ë°œê¸‰ë°›ì€ Client ID
            client_secret (str): ë„¤ì´ë²„ ê°œë°œìì„¼í„°ì—ì„œ ë°œê¸‰ë°›ì€ Client Secret
        """
        self.client_id = "nML9kslg3kN6ObjrujI3"
        self.client_secret = "UynDCaMJCt"
        self.base_url = "https://openapi.naver.com/v1/search/blog"
        
        # ë‹¤ì–‘í•œ User-Agent ëª©ë¡
        self.user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/121.0',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/120.0',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Safari/605.1.15',
            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        ]
    
    def _get_random_user_agent(self):
        """ëœë¤ User-Agent ë°˜í™˜"""
        return random.choice(self.user_agents)
    
    def _random_delay(self, min_delay=1, max_delay=3):
        """ëœë¤ ì§€ì—° ì‹œê°„"""
        delay = random.uniform(min_delay, max_delay)
        print(f"   ì ì‹œ ëŒ€ê¸° ì¤‘... ({delay:.1f}ì´ˆ)")
        time.sleep(delay)
    
    def search_blog(self, query, display=10, start=1, sort="sim"):
        """
        ë¸”ë¡œê·¸ ê²€ìƒ‰
        
        Args:
            query (str): ê²€ìƒ‰ì–´
            display (int): ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥ ê±´ìˆ˜ (1~100)
            start (int): ê²€ìƒ‰ ì‹œì‘ ìœ„ì¹˜ (1~1000)
            sort (str): ì •ë ¬ ì˜µì…˜ (sim: ì •í™•ë„ìˆœ, date: ë‚ ì§œìˆœ)
        
        Returns:
            dict: ë¸”ë¡œê·¸ ê²€ìƒ‰ ê²°ê³¼
        """
        headers = {
            "X-Naver-Client-Id": self.client_id,
            "X-Naver-Client-Secret": self.client_secret,
            "User-Agent": self._get_random_user_agent(),
            "Accept": "application/json",
            "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
            "Accept-Encoding": "gzip, deflate, br",
            "Connection": "keep-alive",
            "Upgrade-Insecure-Requests": "1"
        }
        
        params = {
            "query": query,
            "display": display,
            "start": start,
            "sort": sort
        }
        
        try:
            response = requests.get(self.base_url, headers=headers, params=params)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            print(f"API ìš”ì²­ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return None
    
    def get_blog_content_with_selenium(self, blog_url, max_retries=3):
        """
        Seleniumì„ ì‚¬ìš©í•˜ì—¬ ë¸”ë¡œê·¸ URLì—ì„œ ë³¸ë¬¸ ë‚´ìš©ì„ ì¶”ì¶œ (ìŠ¤í…”ìŠ¤ ëª¨ë“œ)
        """
        options = Options()
        options.add_argument('--headless')
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-blink-features=AutomationControlled')
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        
        # ëœë¤ User-Agent ì‚¬ìš©
        user_agent = self._get_random_user_agent()
        options.add_argument(f'--user-agent={user_agent}')
        
        # ì¶”ê°€ ìŠ¤í…”ìŠ¤ ì˜µì…˜ë“¤
        options.add_argument('--disable-web-security')
        options.add_argument('--allow-running-insecure-content')
        options.add_argument('--disable-extensions')
        options.add_argument('--disable-plugins')
        options.add_argument('--disable-images')  # ì´ë¯¸ì§€ ë¡œë”© ë¹„í™œì„±í™”ë¡œ ì†ë„ í–¥ìƒ
        
        # ìœˆë„ìš° í¬ê¸° ëœë¤í™”
        window_sizes = ['1920,1080', '1366,768', '1440,900', '1536,864']
        options.add_argument(f'--window-size={random.choice(window_sizes)}')

        try:
            service = Service(ChromeDriverManager().install())
            driver = webdriver.Chrome(service=service, options=options)
            
            # WebDriver ê°ì§€ ë°©ì§€ ìŠ¤í¬ë¦½íŠ¸
            driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            driver.execute_script("Object.defineProperty(navigator, 'plugins', {get: () => [1, 2, 3, 4, 5]})")
            driver.execute_script("Object.defineProperty(navigator, 'languages', {get: () => ['ko-KR', 'ko']})")
            
            # ëœë¤ ì§€ì—° í›„ í˜ì´ì§€ ë¡œë“œ
            self._random_delay(1, 2)
            driver.get(blog_url)
            
            # í˜ì´ì§€ ë¡œë”© ì™„ë£Œê¹Œì§€ ëœë¤ ëŒ€ê¸°
            loading_delay = random.uniform(2, 4)
            time.sleep(loading_delay)
            
            # ì‚¬ëŒì²˜ëŸ¼ í–‰ë™ ì‹œë®¬ë ˆì´ì…˜
            self._simulate_human_behavior(driver)
            
            # ë„¤ì´ë²„ ë¸”ë¡œê·¸ì¸ ê²½ìš° iframe ì²˜ë¦¬
            if 'blog.naver.com' in blog_url:
                return self._extract_naver_blog_selenium_enhanced(driver, blog_url)
            
            # í‹°ìŠ¤í† ë¦¬ ë¸”ë¡œê·¸ ë³¸ë¬¸ ì¶”ì¶œ
            content = self._extract_tistory_content_selenium(driver)
            if content:
                return content

            # ì¼ë°˜ì ì¸ ë¸”ë¡œê·¸ ë³¸ë¬¸ ì¶”ì¶œ
            content = self._extract_general_content_selenium(driver)
            if content:
                return content

            return {"title": "ì œëª©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ", "content": "ë³¸ë¬¸ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
            
        except Exception as e:
            print(f"Seleniumì„ ì‚¬ìš©í•œ ë¸”ë¡œê·¸ ë‚´ìš© ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            return {"title": "ì œëª©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ", "content": "ë³¸ë¬¸ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
        finally:
            try:
                driver.quit()
            except:
                pass

    def _simulate_human_behavior(self, driver):
        """ì‚¬ëŒì²˜ëŸ¼ í–‰ë™í•˜ëŠ” ì‹œë®¬ë ˆì´ì…˜"""
        try:
            # ëœë¤ ìŠ¤í¬ë¡¤
            scroll_count = random.randint(1, 3)
            for _ in range(scroll_count):
                scroll_amount = random.randint(200, 800)
                driver.execute_script(f"window.scrollBy(0, {scroll_amount});")
                time.sleep(random.uniform(0.5, 1.5))
            
            # í˜ì´ì§€ ìƒë‹¨ìœ¼ë¡œ ëŒì•„ê°€ê¸°
            driver.execute_script("window.scrollTo(0, 0);")
            time.sleep(random.uniform(0.5, 1))
            
        except Exception:
            pass  # ìŠ¤í¬ë¡¤ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰

    def _scroll_for_more_content(self, driver, display):
        """ë” ë§ì€ ë¸”ë¡œê·¸ë¥¼ ì°¾ê¸° ìœ„í•´ í˜ì´ì§€ ìŠ¤í¬ë¡¤"""
        try:
            # í˜ì´ì§€ ìŠ¤í¬ë¡¤ ë°˜ë³µ
            for _ in range(display - 5):
                # ìŠ¤í¬ë¡¤ ë‹¤ìš´
                driver.execute_script("window.scrollBy(0, 1000);")
                time.sleep(random.uniform(0.5, 1))
            
            # ìŠ¤í¬ë¡¤ ë§ˆì§€ë§‰ ìœ„ì¹˜ë¡œ ì´ë™
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(random.uniform(0.5, 1))
            
        except Exception as e:
            print(f"ë” ë§ì€ ë¸”ë¡œê·¸ë¥¼ ì°¾ê¸° ìœ„í•´ í˜ì´ì§€ ìŠ¤í¬ë¡¤ ì‹¤íŒ¨: {e}")

    def _extract_naver_blog_selenium_enhanced(self, driver, blog_url):
        """í–¥ìƒëœ ë„¤ì´ë²„ ë¸”ë¡œê·¸ Selenium ì¶”ì¶œ"""
        try:
            # ë„¤ì´ë²„ ë¸”ë¡œê·¸ëŠ” iframeì„ ì‚¬ìš©í•˜ë¯€ë¡œ iframeìœ¼ë¡œ ì „í™˜
            iframes = driver.find_elements(By.TAG_NAME, "iframe")
            
            title = "ì œëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ"
            content = ""
            
            # ë©”ì¸ í˜ì´ì§€ì—ì„œ ì œëª© ì°¾ê¸°
            title_selectors = [
                '.blog_title',
                '.se-title-text', 
                '.pcol1 .title_area .title',
                'h1',
                'h2',
                '.title'
            ]
            
            for selector in title_selectors:
                try:
                    title_elem = driver.find_element(By.CSS_SELECTOR, selector)
                    if title_elem and title_elem.text.strip():
                        title = title_elem.text.strip()
                        break
                except:
                    continue
            
            # iframeì—ì„œ ë³¸ë¬¸ ì°¾ê¸°
            for iframe in iframes:
                try:
                    driver.switch_to.frame(iframe)
                    time.sleep(2)
                    
                    # ë‹¤ì–‘í•œ ì„ íƒìë¡œ ë³¸ë¬¸ ì°¾ê¸°
                    content_selectors = [
                        '.se-main-container',
                        '.se-component-content',
                        '.se-text',
                        '.se-text-paragraph',
                        '.post-view',
                        '.post_ct',
                        '.blog_view',
                        '.contents_style',
                        'body'
                    ]
                    
                    for selector in content_selectors:
                        try:
                            content_elem = driver.find_element(By.CSS_SELECTOR, selector)
                            if content_elem:
                                content_text = content_elem.text.strip()
                                if len(content_text) > 50:  # ì¶©ë¶„í•œ ë‚´ìš©ì´ ìˆëŠ” ê²½ìš°
                                    content = content_text
                                    break
                        except:
                            continue
                    
                    if content:
                        break
                        
                    driver.switch_to.default_content()
                    
                except Exception as e:
                    driver.switch_to.default_content()
                    continue
            
            # iframeì—ì„œ ì°¾ì§€ ëª»í•œ ê²½ìš° ë©”ì¸ í˜ì´ì§€ì—ì„œ ì°¾ê¸°
            if not content:
                try:
                    # í˜ì´ì§€ ì „ì²´ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
                    body_text = driver.find_element(By.TAG_NAME, "body").text
                    if len(body_text) > 100:
                        # ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±°í•˜ê³  ì˜ë¯¸ìˆëŠ” ë¶€ë¶„ë§Œ ì¶”ì¶œ
                        lines = body_text.split('\n')
                        meaningful_lines = []
                        for line in lines:
                            line = line.strip()
                            if (len(line) > 10 and 
                                not line.startswith('http') and 
                                'ëŒ“ê¸€' not in line and 
                                'ê³µê°' not in line and
                                'ì´ì›ƒ' not in line):
                                meaningful_lines.append(line)
                        
                        if meaningful_lines:
                            content = '\n'.join(meaningful_lines[:20])  # ì²˜ìŒ 20ì¤„ë§Œ
                except:
                    pass
            
            if not content:
                content = "ë³¸ë¬¸ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            return {"title": title, "content": self._clean_text(content)}
            
        except Exception as e:
            print(f"ë„¤ì´ë²„ ë¸”ë¡œê·¸ í–¥ìƒëœ Selenium ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            return {"title": "ì œëª©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ", "content": "ë³¸ë¬¸ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

    def _extract_naver_blog_content_selenium(self, driver):
        """ê¸°ë³¸ ë„¤ì´ë²„ ë¸”ë¡œê·¸ Selenium ì¶”ì¶œ (í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€)"""
        return self._extract_naver_blog_selenium_enhanced(driver, driver.current_url)

    def _extract_tistory_content_selenium(self, driver):
        """Seleniumì„ ì‚¬ìš©í•˜ì—¬ í‹°ìŠ¤í† ë¦¬ ë¸”ë¡œê·¸ ë³¸ë¬¸ ì¶”ì¶œ"""
        try:
            title = driver.find_element(By.CSS_SELECTOR, '.entry-title').text
            content = driver.find_element(By.CSS_SELECTOR, '.entry-content').text
            return {"title": title, "content": self._clean_text(content)}
        except Exception as e:
            print(f"í‹°ìŠ¤í† ë¦¬ ë¸”ë¡œê·¸ Selenium ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            return None

    def _extract_general_content_selenium(self, driver):
        """Seleniumì„ ì‚¬ìš©í•˜ì—¬ ì¼ë°˜ì ì¸ ë¸”ë¡œê·¸ ë³¸ë¬¸ ì¶”ì¶œ"""
        try:
            title = driver.find_element(By.TAG_NAME, 'h1').text
            content = driver.find_element(By.TAG_NAME, 'body').text
            return {"title": title, "content": self._clean_text(content)}
        except Exception as e:
            print(f"ì¼ë°˜ ë¸”ë¡œê·¸ Selenium ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            return None

    def _clean_text(self, text):
        """í…ìŠ¤íŠ¸ ì •ë¦¬"""
        if not text:
            return "ë³¸ë¬¸ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ì—°ì†ëœ ê³µë°±ê³¼ ì¤„ë°”ê¿ˆ ì •ë¦¬
        text = re.sub(r'\n\s*\n', '\n\n', text)
        text = re.sub(r' +', ' ', text)
        
        # CSV ì €ì¥ì„ ìœ„í•´ ë”°ì˜´í‘œì™€ ì‰¼í‘œ ì²˜ë¦¬
        text = text.replace('"', '""')  # CSVì—ì„œ ë”°ì˜´í‘œ ì´ìŠ¤ì¼€ì´í”„
        
        return text.strip()
    
    def save_to_csv(self, search_query, results, filename="blog_search_results.csv"):
        """
        ê²€ìƒ‰ ê²°ê³¼ë¥¼ CSV íŒŒì¼ì— ì €ì¥
        
        Args:
            search_query (str): ê²€ìƒ‰ì–´
            results (list): ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            filename (str): ì €ì¥í•  íŒŒì¼ëª…
        """
        # CSV íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        file_exists = os.path.isfile(filename)
        
        try:
            with open(filename, 'a', newline='', encoding='utf-8-sig') as csvfile:
                fieldnames = ['ê²€ìƒ‰ì–´', 'ë³¸ë¬¸ë‚´ìš©', 'ì œëª©', 'ë¸”ë¡œê±°', 'ì‘ì„±ì¼', 'ë§í¬']
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                
                # íŒŒì¼ì´ ìƒˆë¡œ ìƒì„±ë˜ëŠ” ê²½ìš° í—¤ë” ì‘ì„±
                if not file_exists:
                    writer.writeheader()
                
                # ê²€ìƒ‰ ê²°ê³¼ ì €ì¥
                for result in results:
                    if result.get('content') and result['content'].get('content'):
                        content_text = result['content']['content']
                    else:
                        content_text = result.get('description', "ë³¸ë¬¸ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    
                    writer.writerow({
                        'ê²€ìƒ‰ì–´': search_query,
                        'ë³¸ë¬¸ë‚´ìš©': content_text,
                        'ì œëª©': result.get('title', ''),
                        'ë¸”ë¡œê±°': result.get('bloggername', ''),
                        'ì‘ì„±ì¼': result.get('postdate', ''),
                        'ë§í¬': result.get('link', '')
                    })
            
            print(f"\nâœ… ê²€ìƒ‰ ê²°ê³¼ê°€ '{filename}' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return filename
            
        except Exception as e:
            print(f"âŒ CSV íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return None
    
    def search_and_get_content(self, query, display=5, sort="sim", get_content=True, save_csv=True):
        """
        ë¸”ë¡œê·¸ ê²€ìƒ‰ í›„ ë³¸ë¬¸ ë‚´ìš©ê¹Œì§€ ê°€ì ¸ì˜¤ê¸° (ê°œì„ ëœ ë²„ì „ - ëŒ€ëŸ‰ ìˆ˜ì§‘ ì§€ì›)
        
        Args:
            query (str): ê²€ìƒ‰ì–´
            display (int): ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥ ê±´ìˆ˜ (ìµœëŒ€ 1000ê°œê¹Œì§€ ì§€ì›)
            sort (str): ì •ë ¬ ì˜µì…˜
            get_content (bool): ë³¸ë¬¸ ë‚´ìš©ì„ ê°€ì ¸ì˜¬ì§€ ì—¬ë¶€
            save_csv (bool): CSV íŒŒì¼ë¡œ ì €ì¥í• ì§€ ì—¬ë¶€
        
        Returns:
            list: ë¸”ë¡œê·¸ ê²€ìƒ‰ ê²°ê³¼ì™€ ë³¸ë¬¸ ë‚´ìš©
        """
        print(f"\n=== '{query}' ë¸”ë¡œê·¸ ê²€ìƒ‰ ê²°ê³¼ (API ì‚¬ìš©) ===")
        
        all_results = []
        collected_count = 0
        start_position = 1
        
        # APIëŠ” í•œ ë²ˆì— ìµœëŒ€ 100ê°œê¹Œì§€ë§Œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì—¬ëŸ¬ ë²ˆ í˜¸ì¶œ
        while collected_count < display:
            # ì´ë²ˆ í˜¸ì¶œì—ì„œ ê°€ì ¸ì˜¬ ê°œìˆ˜ ê³„ì‚°
            current_display = min(100, display - collected_count)
            
            print(f"API í˜¸ì¶œ {(start_position-1)//100 + 1}: {start_position}~{start_position + current_display - 1}ë²ˆì§¸ ê²°ê³¼ ìˆ˜ì§‘ ì¤‘...")
            
            # ë¸”ë¡œê·¸ ê²€ìƒ‰
            search_results = self.search_blog(query, current_display, start_position, sort=sort)
            
            if not search_results or not search_results.get('items'):
                print(f"ë” ì´ìƒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. (ì´ {collected_count}ê°œ ìˆ˜ì§‘)")
                break
            
            current_items = search_results['items']
            print(f"ì´ë²ˆ í˜¸ì¶œì—ì„œ {len(current_items)}ê°œ ë¸”ë¡œê·¸ ë°œê²¬")
            
            # ê²°ê³¼ ì²˜ë¦¬
            for i, item in enumerate(current_items, collected_count + 1):
                blog_info = {
                    'rank': i,
                    'title': item.get('title', 'ì œëª© ì—†ìŒ'),
                    'description': item.get('description', 'ì„¤ëª… ì—†ìŒ'),
                    'link': item.get('link', ''),
                    'bloggername': item.get('bloggername', 'ì•Œ ìˆ˜ ì—†ìŒ'),
                    'postdate': item.get('postdate', 'ë‚ ì§œ ì—†ìŒ'),
                    'content': None
                }
                
                print(f"{i}. {blog_info['title']}")
                print(f"   ë¸”ë¡œê±°: {blog_info['bloggername']}")
                print(f"   ì‘ì„±ì¼: {blog_info['postdate']}")
                print(f"   ë§í¬: {blog_info['link']}")
                print(f"   ìš”ì•½: {blog_info['description']}")
                
                if get_content and blog_info['link']:
                    print("   ë³¸ë¬¸ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
                    content_data = self.get_blog_content_with_selenium(blog_info['link'])
                    blog_info['content'] = content_data
                    
                    if content_data and content_data.get('content'):
                        print(f"   ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸°: {content_data['content'][:100]}...")
                    else:
                        print("   ë³¸ë¬¸ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    
                    # ìš”ì²­ ê°„ê²© ì¡°ì ˆ (ë„ˆë¬´ ë¹ ë¥¸ ìš”ì²­ ë°©ì§€) - ëœë¤ ì§€ì—°
                    if i < display:  # ë§ˆì§€ë§‰ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ
                        self._random_delay(1, 3)  # APIëŠ” ë” ë¹ ë¥´ê²Œ
                
                print("-" * 60)
                all_results.append(blog_info)
                collected_count += 1
                
                # ëª©í‘œ ê°œìˆ˜ì— ë„ë‹¬í•˜ë©´ ì¤‘ë‹¨
                if collected_count >= display:
                    break
            
            # ë‹¤ìŒ í˜ì´ì§€ ì¤€ë¹„
            start_position += current_display
            
            # API í˜¸ì¶œ ê°„ ì§€ì—° (ì„œë²„ ë¶€í•˜ ë°©ì§€)
            if collected_count < display and len(current_items) == current_display:
                print("ë‹¤ìŒ í˜ì´ì§€ ì¤€ë¹„ ì¤‘...")
                self._random_delay(1, 2)
            else:
                # ë” ì´ìƒ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì¤‘ë‹¨
                break
        
        print(f"\nì´ {len(all_results)}ê°œì˜ ë¸”ë¡œê·¸ ìˆ˜ì§‘ ì™„ë£Œ!")
        
        # CSV íŒŒì¼ë¡œ ì €ì¥
        if save_csv and all_results:
            self.save_to_csv(query, all_results)
        
        return all_results

    def search_blog_without_api(self, query, display=5):
        """
        API ì—†ì´ ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰ í˜ì´ì§€ë¥¼ ì§ì ‘ í¬ë¡¤ë§
        """
        options = Options()
        options.add_argument('--headless')
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-blink-features=AutomationControlled')
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        
        # ëœë¤ User-Agent ì‚¬ìš©
        user_agent = self._get_random_user_agent()
        options.add_argument(f'--user-agent={user_agent}')
        
        # ì¶”ê°€ ìŠ¤í…”ìŠ¤ ì˜µì…˜ë“¤
        options.add_argument('--disable-web-security')
        options.add_argument('--allow-running-insecure-content')
        options.add_argument('--disable-extensions')
        options.add_argument('--disable-plugins')
        options.add_argument('--disable-images')
        
        # ìœˆë„ìš° í¬ê¸° ëœë¤í™”
        window_sizes = ['1920,1080', '1366,768', '1440,900', '1536,864']
        options.add_argument(f'--window-size={random.choice(window_sizes)}')

        try:
            service = Service(ChromeDriverManager().install())
            driver = webdriver.Chrome(service=service, options=options)
            
            # WebDriver ê°ì§€ ë°©ì§€ ìŠ¤í¬ë¦½íŠ¸
            driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            driver.execute_script("Object.defineProperty(navigator, 'plugins', {get: () => [1, 2, 3, 4, 5]})")
            driver.execute_script("Object.defineProperty(navigator, 'languages', {get: () => ['ko-KR', 'ko']})")
            
            blog_results = []
            seen_links = set()
            page = 1
            
            # ì—¬ëŸ¬ í˜ì´ì§€ì—ì„œ ë¸”ë¡œê·¸ ìˆ˜ì§‘
            while len(blog_results) < display and page <= 10:  # ìµœëŒ€ 10í˜ì´ì§€ê¹Œì§€
                # í˜ì´ì§€ë³„ ê²€ìƒ‰ URL (start íŒŒë¼ë¯¸í„°ë¡œ í˜ì´ì§€ë„¤ì´ì…˜)
                start_num = (page - 1) * 10 + 1
                search_url = f"https://search.naver.com/search.naver?where=blog&query={urllib.parse.quote(query)}&start={start_num}"
                
                print(f"   í˜ì´ì§€ {page} ê²€ìƒ‰ ì¤‘... (ëª©í‘œ: {display}ê°œ, í˜„ì¬: {len(blog_results)}ê°œ)")
                self._random_delay(1, 2)
                driver.get(search_url)
                
                # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
                loading_delay = random.uniform(3, 5)
                time.sleep(loading_delay)
                
                # ì‚¬ëŒì²˜ëŸ¼ í–‰ë™ ì‹œë®¬ë ˆì´ì…˜
                self._simulate_human_behavior(driver)
                
                # í˜ì´ì§€ ëê¹Œì§€ ìŠ¤í¬ë¡¤í•˜ì—¬ ëª¨ë“  ì½˜í…ì¸  ë¡œë“œ
                self._scroll_to_load_all_content(driver)
                
                # í˜„ì¬ í˜ì´ì§€ì—ì„œ ë¸”ë¡œê·¸ ë§í¬ ì°¾ê¸°
                page_links = self._extract_blog_links_from_page(driver, seen_links)
                
                if not page_links:
                    print(f"   í˜ì´ì§€ {page}ì—ì„œ ìƒˆë¡œìš´ ë¸”ë¡œê·¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                    break
                
                # ê²°ê³¼ì— ì¶”ê°€
                for link_info in page_links:
                    if len(blog_results) >= display:
                        break
                    blog_results.append(link_info)
                    print(f"   ë¸”ë¡œê·¸ {len(blog_results)}: {link_info['title'][:50]}...")
                
                page += 1
                
                # í˜ì´ì§€ ê°„ ì§€ì—°
                if len(blog_results) < display and page <= 10:
                    self._random_delay(2, 4)
            
            print(f"   ì´ {len(blog_results)}ê°œ ë¸”ë¡œê·¸ ìˆ˜ì§‘ ì™„ë£Œ!")
            return blog_results
            
        except Exception as e:
            print(f"ë„¤ì´ë²„ ê²€ìƒ‰ í˜ì´ì§€ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            return []
        finally:
            try:
                driver.quit()
            except:
                pass

    def _scroll_to_load_all_content(self, driver):
        """í˜ì´ì§€ ëê¹Œì§€ ìŠ¤í¬ë¡¤í•˜ì—¬ ëª¨ë“  ì½˜í…ì¸  ë¡œë“œ"""
        try:
            last_height = driver.execute_script("return document.body.scrollHeight")
            scroll_count = 0
            max_scrolls = 10  # ìµœëŒ€ ìŠ¤í¬ë¡¤ íšŸìˆ˜
            
            while scroll_count < max_scrolls:
                # í˜ì´ì§€ ëê¹Œì§€ ìŠ¤í¬ë¡¤
                driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(random.uniform(1, 2))
                
                # ìƒˆë¡œìš´ ë†’ì´ í™•ì¸
                new_height = driver.execute_script("return document.body.scrollHeight")
                
                # ë” ì´ìƒ ë¡œë“œí•  ì½˜í…ì¸ ê°€ ì—†ìœ¼ë©´ ì¤‘ë‹¨
                if new_height == last_height:
                    break
                    
                last_height = new_height
                scroll_count += 1
                
                # ì¤‘ê°„ì¤‘ê°„ ìŠ¤í¬ë¡¤ (ë” ìì—°ìŠ¤ëŸ½ê²Œ)
                for _ in range(3):
                    scroll_position = random.randint(100, new_height - 100)
                    driver.execute_script(f"window.scrollTo(0, {scroll_position});")
                    time.sleep(random.uniform(0.3, 0.7))
                    
        except Exception as e:
            print(f"ìŠ¤í¬ë¡¤ ì¤‘ ì˜¤ë¥˜: {e}")

    def _extract_blog_links_from_page(self, driver, seen_links):
        """í˜„ì¬ í˜ì´ì§€ì—ì„œ ë¸”ë¡œê·¸ ë§í¬ ì¶”ì¶œ"""
        page_results = []
        
        try:
            # ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ ë¸”ë¡œê·¸ ë§í¬ ì°¾ê¸°
            selectors = [
                "a[href*='blog.naver.com']",
                "a[href*='blog.naver.com/PostView']",
                "a[href*='blog.naver.com'][href*='/22']",  # 222, 223 ë“±
                ".blog_area a",
                ".total_area a[href*='blog.naver.com']",
                ".lst_total a[href*='blog.naver.com']"
            ]
            
            all_links = []
            for selector in selectors:
                try:
                    links = driver.find_elements(By.CSS_SELECTOR, selector)
                    all_links.extend(links)
                except:
                    continue
            
            print(f"   ì´ {len(all_links)}ê°œ ë§í¬ ë°œê²¬")
            
            for link in all_links:
                try:
                    href = link.get_attribute('href')
                    if not href or href in seen_links:
                        continue
                    
                    # ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ë§í¬ í•„í„°ë§ (ì¡°ê±´ ëŒ€í­ ì™„í™”)
                    if (href and 'blog.naver.com' in href and 
                        # ë” ê´€ëŒ€í•œ ì¡°ê±´ë“¤
                        (('/223' in href) or ('/222' in href) or ('/221' in href) or ('/220' in href) or
                         ('/PostView.naver' in href) or ('/post/' in href) or
                         ('logNo=' in href) or ('blogId=' in href) or
                         (href.count('/') >= 4 and not href.endswith('.naver') and 
                          not 'prologue' in href and not 'category' in href))):
                        
                        seen_links.add(href)
                        
                        # ì œëª© ì¶”ì¶œ (ë” ì ê·¹ì ìœ¼ë¡œ)
                        title = self._extract_title_from_link(link)
                        
                        if title and len(title) > 1:  # ì¡°ê±´ ë”ìš± ì™„í™”
                            page_results.append({
                                'title': title,
                                'link': href,
                                'description': "ì„¤ëª… ì—†ìŒ",
                                'bloggername': "ì•Œ ìˆ˜ ì—†ìŒ", 
                                'postdate': "ë‚ ì§œ ì—†ìŒ"
                            })
                            
                except Exception as e:
                    continue
            
            return page_results
            
        except Exception as e:
            print(f"ë¸”ë¡œê·¸ ë§í¬ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            return []

    def _extract_title_from_link(self, link):
        """ë§í¬ì—ì„œ ì œëª© ì¶”ì¶œ (ê°œì„ ëœ ë²„ì „)"""
        try:
            # 1. ë§í¬ í…ìŠ¤íŠ¸ì—ì„œ ì§ì ‘ ì¶”ì¶œ
            title = link.text.strip()
            if title and len(title) > 3:
                return self._clean_title(title)
            
            # 2. ë¶€ëª¨ ìš”ì†Œë“¤ì—ì„œ ì œëª© ì°¾ê¸° (ë” ì ê·¹ì ìœ¼ë¡œ)
            current = link
            for level in range(8):  # 8ë ˆë²¨ê¹Œì§€ í™•ì¥
                try:
                    current = current.find_element(By.XPATH, "..")
                    parent_text = current.text.strip()
                    
                    if parent_text and len(parent_text) > 3:
                        lines = parent_text.split('\n')
                        for line in lines:
                            line = line.strip()
                            # ë” ê´€ëŒ€í•œ ì œëª© ì¡°ê±´
                            if (len(line) > 2 and len(line) < 300 and 
                                not line.startswith('http') and
                                not line.startswith('www') and
                                'ë¸”ë¡œê·¸' not in line[:10] and
                                'ë„¤ì´ë²„' not in line[:10]):
                                return self._clean_title(line)
                except:
                    break
            
            # 3. ì£¼ë³€ ìš”ì†Œì—ì„œ ì œëª© ì°¾ê¸°
            try:
                # í˜•ì œ ìš”ì†Œë“¤ í™•ì¸
                siblings = current.find_elements(By.XPATH, "../*")
                for sibling in siblings:
                    sibling_text = sibling.text.strip()
                    if (sibling_text and len(sibling_text) > 3 and len(sibling_text) < 200 and
                        not sibling_text.startswith('http')):
                        return self._clean_title(sibling_text)
            except:
                pass
            
            # 4. URLì—ì„œ ì¶”ì¶œ
            href = link.get_attribute('href')
            if href:
                url_parts = href.split('/')
                if len(url_parts) > 3:
                    blog_id = url_parts[3] if len(url_parts) > 3 else "unknown"
                    return f"ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ - {blog_id}"
            
            return "ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸"
            
        except Exception as e:
            return "ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸"

    def _clean_title(self, title):
        """ì œëª© ì •ë¦¬"""
        if not title:
            return "ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸"
        
        # ì²« ë²ˆì§¸ ì¤„ë§Œ ì‚¬ìš©
        title = title.split('\n')[0].strip()
        
        # HTML íƒœê·¸ ì œê±°
        title = title.replace('<b>', '').replace('</b>', '')
        title = title.replace('<em>', '').replace('</em>', '')
        title = title.replace('...', '').strip()
        
        # íŠ¹ìˆ˜ ë¬¸ì ì •ë¦¬
        title = re.sub(r'[^\w\sê°€-í£ã„±-ã…ã…-ã…£]', ' ', title)
        title = re.sub(r'\s+', ' ', title).strip()
        
        return title if len(title) > 1 else "ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸"

    def search_and_get_content_without_api(self, query, display=5, get_content=True, save_csv=True):
        """
        API ì—†ì´ ë¸”ë¡œê·¸ ê²€ìƒ‰ í›„ ë³¸ë¬¸ ë‚´ìš©ê¹Œì§€ ê°€ì ¸ì˜¤ê¸°
        """
        print(f"\n=== '{query}' ë¸”ë¡œê·¸ ê²€ìƒ‰ ê²°ê³¼ (API ë¯¸ì‚¬ìš©) ===")
        
        # ë„¤ì´ë²„ ê²€ìƒ‰ í˜ì´ì§€ì—ì„œ ë¸”ë¡œê·¸ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
        search_results = self.search_blog_without_api(query, display)
        
        if not search_results:
            print("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        results = []
        print(f"ì´ {len(search_results)}ê°œì˜ ë¸”ë¡œê·¸ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
        print("-" * 60)
        
        # ê²€ìƒ‰ ê²°ê³¼ ìˆœì„œ ëœë¤í™” (íŒ¨í„´ ìˆ¨ê¸°ê¸°)
        random.shuffle(search_results)
        
        for i, item in enumerate(search_results, 1):
            blog_info = {
                'rank': i,
                'title': item.get('title', 'ì œëª© ì—†ìŒ'),
                'description': item.get('description', 'ì„¤ëª… ì—†ìŒ'),
                'link': item.get('link', ''),
                'bloggername': item.get('bloggername', 'ì•Œ ìˆ˜ ì—†ìŒ'),
                'postdate': item.get('postdate', 'ë‚ ì§œ ì—†ìŒ'),
                'content': None
            }
            
            print(f"{i}. {blog_info['title']}")
            print(f"   ë¸”ë¡œê±°: {blog_info['bloggername']}")
            print(f"   ì‘ì„±ì¼: {blog_info['postdate']}")
            print(f"   ë§í¬: {blog_info['link']}")
            print(f"   ìš”ì•½: {blog_info['description']}")
            
            if get_content and blog_info['link']:
                print("   ë³¸ë¬¸ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
                
                # ê²€ìƒ‰ê³¼ í¬ë¡¤ë§ ì‚¬ì´ì— ë” ê¸´ ì§€ì—° (ìì—°ìŠ¤ëŸ¬ìš´ íŒ¨í„´)
                self._random_delay(5, 10)
                
                content_data = self.get_blog_content_with_selenium(blog_info['link'])
                blog_info['content'] = content_data
                
                if content_data and content_data.get('content'):
                    print(f"   ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸°: {content_data['content'][:100]}...")
                else:
                    print("   ë³¸ë¬¸ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
                # ë¸”ë¡œê·¸ ê°„ ê°„ê²© (ë§ˆì§€ë§‰ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ)
                if i < len(search_results):
                    self._random_delay(3, 8)  # ë” ê¸´ ì§€ì—°
            
            print("-" * 60)
            results.append(blog_info)
        
        # CSV íŒŒì¼ë¡œ ì €ì¥
        if save_csv and results:
            self.save_to_csv(query, results, "blog_search_results_no_api.csv")
        
        return results

def print_search_results(results, search_type):
    """
    ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        results (dict): API ê²€ìƒ‰ ê²°ê³¼
        search_type (str): ê²€ìƒ‰ íƒ€ì…
    """
    if not results:
        print("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"\n=== {search_type} ê²€ìƒ‰ ê²°ê³¼ ===")
    print(f"ì´ ê²€ìƒ‰ ê²°ê³¼: {results.get('total', 0)}ê±´")
    print(f"í˜„ì¬ í˜ì´ì§€: {results.get('start', 0)}~{results.get('start', 0) + len(results.get('items', [])) - 1}")
    print("-" * 50)
    
    for i, item in enumerate(results.get('items', []), 1):
        print(f"{i}. {item.get('title', 'ì œëª© ì—†ìŒ')}")
        if 'description' in item:
            print(f"   ì„¤ëª…: {item['description']}")
        if 'link' in item:
            print(f"   ë§í¬: {item['link']}")
        if 'bloggername' in item:
            print(f"   ë¸”ë¡œê±°: {item['bloggername']}")
        if 'postdate' in item:
            print(f"   ì‘ì„±ì¼: {item['postdate']}")
        if 'author' in item:
            print(f"   ì €ì: {item['author']}")
        if 'publisher' in item:
            print(f"   ì¶œíŒì‚¬: {item['publisher']}")
        if 'pubdate' in item:
            print(f"   ì¶œê°„ì¼: {item['pubdate']}")
        if 'address' in item:
            print(f"   ì£¼ì†Œ: {item['address']}")
        if 'telephone' in item:
            print(f"   ì „í™”ë²ˆí˜¸: {item['telephone']}")
        print()

def main():
    """
    ë©”ì¸ í•¨ìˆ˜ - ë¸”ë¡œê·¸ ê²€ìƒ‰ ë° ë³¸ë¬¸ í¬ë¡¤ë§
    """
    # API í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    blog_api = NaverBlogSearchAPI()
    
    print("=== ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰ ë° ë³¸ë¬¸ í¬ë¡¤ë§ ===\n")
    
    # ê²€ìƒ‰ ë°©ë²• ì„ íƒ
    print("ê²€ìƒ‰ ë°©ë²•ì„ ì„ íƒí•˜ì„¸ìš”:")
    print("1. API ì‚¬ìš© (ë¹ ë¥´ì§€ë§Œ ë¡œê·¸ê°€ ë‚¨ìŒ)")
    print("2. ì§ì ‘ í¬ë¡¤ë§ (ëŠë¦¬ì§€ë§Œ ë” ì•ˆì „í•¨)")
    
    while True:
        choice = input("ì„ íƒ (1 ë˜ëŠ” 2): ").strip()
        if choice in ['1', '2']:
            break
        print("1 ë˜ëŠ” 2ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    # ê²€ìƒ‰ì–´ ì…ë ¥ (ìµœëŒ€ 10ê°œ)
    print("\nê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ìµœëŒ€ 10ê°œê¹Œì§€ ê°€ëŠ¥):")
    print("- ê²€ìƒ‰ì–´ë¥¼ í•˜ë‚˜ì”© ì…ë ¥í•˜ê³  Enterë¥¼ ëˆ„ë¥´ì„¸ìš”")
    print("- ì…ë ¥ì„ ë§ˆì¹˜ë ¤ë©´ ë¹ˆ ì¤„ì—ì„œ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”")
    print("- ë˜ëŠ” ì‰¼í‘œ(,)ë¡œ êµ¬ë¶„í•˜ì—¬ í•œ ë²ˆì— ì…ë ¥í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤")
    
    search_queries = []
    
    # ì²« ë²ˆì§¸ ì…ë ¥ ë°›ê¸°
    first_input = input("ê²€ìƒ‰ì–´ ì…ë ¥: ").strip()
    
    if not first_input:
        print("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return
    
    # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ì—¬ëŸ¬ ê²€ìƒ‰ì–´ì¸ì§€ í™•ì¸
    if ',' in first_input:
        # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ê²€ìƒ‰ì–´ë“¤ ì²˜ë¦¬
        queries = [q.strip() for q in first_input.split(',') if q.strip()]
        search_queries.extend(queries[:10])  # ìµœëŒ€ 10ê°œê¹Œì§€ë§Œ
        print(f"ì…ë ¥ëœ ê²€ìƒ‰ì–´: {search_queries}")
    else:
        # ë‹¨ì¼ ê²€ìƒ‰ì–´ë¡œ ì‹œì‘
        search_queries.append(first_input)
        
        # ì¶”ê°€ ê²€ìƒ‰ì–´ ì…ë ¥ ë°›ê¸°
        for i in range(2, 11):  # 2ë²ˆì§¸ë¶€í„° 10ë²ˆì§¸ê¹Œì§€
            query = input(f"ê²€ìƒ‰ì–´ {i} (Enterë¡œ ì™„ë£Œ): ").strip()
            if not query:
                break
            search_queries.append(query)
    
    if not search_queries:
        print("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return
    
    print(f"\nì´ {len(search_queries)}ê°œì˜ ê²€ìƒ‰ì–´ê°€ ì…ë ¥ë˜ì—ˆìŠµë‹ˆë‹¤:")
    for i, query in enumerate(search_queries, 1):
        print(f"{i}. {query}")
    
    # ê²€ìƒ‰í•  ë¸”ë¡œê·¸ ê°œìˆ˜ ì„ íƒ
    print("\nê° ê²€ìƒ‰ì–´ë‹¹ ê²€ìƒ‰í•  ë¸”ë¡œê·¸ ê°œìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš”:")
    if choice == '1':  # API ì‚¬ìš©
        print("1. 10ê°œ (ë¹ ë¦„)")
        print("2. 50ê°œ (ë³´í†µ)")
        print("3. 100ê°œ (ë§ìŒ)")
        print("4. 200ê°œ (ëŒ€ëŸ‰)")
        print("5. ì§ì ‘ ì…ë ¥")
        
        while True:
            count_choice = input("ì„ íƒ (1-5): ").strip()
            if count_choice in ['1', '2', '3', '4', '5']:
                break
            print("1, 2, 3, 4, ë˜ëŠ” 5ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        # ë¸”ë¡œê·¸ ê°œìˆ˜ ì„¤ì •
        if count_choice == '1':
            display_count = 10
        elif count_choice == '2':
            display_count = 50
        elif count_choice == '3':
            display_count = 100
        elif count_choice == '4':
            display_count = 200
        else:  # count_choice == '5'
            while True:
                try:
                    display_count = int(input("ê²€ìƒ‰í•  ë¸”ë¡œê·¸ ê°œìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš” (1-1000): "))
                    if 1 <= display_count <= 1000:
                        break
                    else:
                        print("1ë¶€í„° 1000 ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                except ValueError:
                    print("ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:  # ì§ì ‘ í¬ë¡¤ë§
        print("1. 5ê°œ (ë¹ ë¦„)")
        print("2. 10ê°œ (ë³´í†µ)")
        print("3. 20ê°œ (ëŠë¦¼)")
        print("4. ì§ì ‘ ì…ë ¥")
        
        while True:
            count_choice = input("ì„ íƒ (1-4): ").strip()
            if count_choice in ['1', '2', '3', '4']:
                break
            print("1, 2, 3, ë˜ëŠ” 4ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        # ë¸”ë¡œê·¸ ê°œìˆ˜ ì„¤ì •
        if count_choice == '1':
            display_count = 5
        elif count_choice == '2':
            display_count = 10
        elif count_choice == '3':
            display_count = 20
        else:  # count_choice == '4'
            while True:
                try:
                    display_count = int(input("ê²€ìƒ‰í•  ë¸”ë¡œê·¸ ê°œìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš” (1-50): "))
                    if 1 <= display_count <= 50:
                        break
                    else:
                        print("1ë¶€í„° 50 ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                except ValueError:
                    print("ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    # ì˜ˆìƒ ì†Œìš” ì‹œê°„ ê³„ì‚° ë° ì•ˆë‚´
    total_blogs = len(search_queries) * display_count
    if choice == '2':  # ì§ì ‘ í¬ë¡¤ë§
        estimated_time = total_blogs * 10  # ë¸”ë¡œê·¸ë‹¹ ì•½ 10ì´ˆ
        print(f"\nâ° ì˜ˆìƒ ì†Œìš” ì‹œê°„: ì•½ {estimated_time//60}ë¶„ {estimated_time%60}ì´ˆ")
        print("ğŸ’¡ ì§ì ‘ í¬ë¡¤ë§ì€ ì•ˆì „í•˜ì§€ë§Œ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤.")
    else:  # API ì‚¬ìš©
        estimated_time = total_blogs * 3  # ë¸”ë¡œê·¸ë‹¹ ì•½ 3ì´ˆ
        print(f"\nâ° ì˜ˆìƒ ì†Œìš” ì‹œê°„: ì•½ {estimated_time//60}ë¶„ {estimated_time%60}ì´ˆ")
    
    print(f"ğŸ“Š ì´ ìˆ˜ì§‘ ì˜ˆì • ë¸”ë¡œê·¸: {total_blogs}ê°œ ({len(search_queries)}ê°œ ê²€ìƒ‰ì–´ Ã— {display_count}ê°œ)")
    
    confirm = input("ê³„ì† ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
    if confirm not in ['y', 'yes', 'ì˜ˆ', 'ã…‡']:
        print("ì‘ì—…ì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
        return
    
    # ê° ê²€ìƒ‰ì–´ì— ëŒ€í•´ ìˆœì°¨ì ìœ¼ë¡œ ê²€ìƒ‰ ì‹¤í–‰
    all_results = []
    total_collected = 0
    
    for i, search_query in enumerate(search_queries, 1):
        print(f"\n{'='*60}")
        print(f"ğŸ” ê²€ìƒ‰ ì§„í–‰: {i}/{len(search_queries)} - '{search_query}'")
        print(f"{'='*60}")
        
        if choice == '1':
            print(f"APIë¥¼ ì‚¬ìš©í•˜ì—¬ '{search_query}' ê²€ìƒ‰ ì¤‘... ({display_count}ê°œ)")
            results = blog_api.search_and_get_content(
                query=search_query,
                display=display_count,
                sort="sim",
                get_content=True,
                save_csv=True
            )
        else:
            print(f"ì§ì ‘ í¬ë¡¤ë§ìœ¼ë¡œ '{search_query}' ê²€ìƒ‰ ì¤‘... ({display_count}ê°œ)")
            results = blog_api.search_and_get_content_without_api(
                query=search_query,
                display=display_count,
                get_content=True,
                save_csv=True
            )
        
        if results:
            all_results.extend(results)
            total_collected += len(results)
            print(f"âœ… '{search_query}' ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ìˆ˜ì§‘")
        else:
            print(f"âŒ '{search_query}' ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
        
        # ê²€ìƒ‰ì–´ ê°„ ê°„ê²© (ë§ˆì§€ë§‰ì´ ì•„ë‹Œ ê²½ìš°)
        if i < len(search_queries):
            print(f"ë‹¤ìŒ ê²€ìƒ‰ì–´ ì¤€ë¹„ ì¤‘... (ì ì‹œ ëŒ€ê¸°)")
            time.sleep(random.uniform(3, 6))
    
    # ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print(f"\n{'='*60}")
    print(f"ğŸ‰ ì „ì²´ ê²€ìƒ‰ ì™„ë£Œ!")
    print(f"{'='*60}")
    print(f"ğŸ“Š ê²€ìƒ‰ì–´ ê°œìˆ˜: {len(search_queries)}ê°œ")
    print(f"ğŸ“Š ì´ ìˆ˜ì§‘ëœ ë¸”ë¡œê·¸: {total_collected}ê°œ")
    print(f"ğŸ“Š í‰ê·  ê²€ìƒ‰ì–´ë‹¹: {total_collected/len(search_queries):.1f}ê°œ")
    
    if total_collected > 0:
        if choice == '1':
            print("ğŸ“„ ëª¨ë“  ê²€ìƒ‰ ê²°ê³¼ê°€ 'blog_search_results.csv' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            print("ğŸ“„ ëª¨ë“  ê²€ìƒ‰ ê²°ê³¼ê°€ 'blog_search_results_no_api.csv' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        print("\nê²€ìƒ‰ì–´ë³„ ìˆ˜ì§‘ ê²°ê³¼:")
        query_counts = {}
        for result in all_results:
            # CSVì—ì„œ ê²€ìƒ‰ì–´ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ê±°ë‚˜, ê²°ê³¼ì—ì„œ ì¶”ì¶œ
            # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ì „ì²´ ê²°ê³¼ë§Œ í‘œì‹œ
            pass
        
        for i, query in enumerate(search_queries, 1):
            print(f"{i}. '{query}': ìˆ˜ì§‘ ì™„ë£Œ")
    else:
        print("âŒ ì „ì²´ ê²€ìƒ‰ì—ì„œ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main() 